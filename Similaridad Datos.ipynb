{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "from joblib import dump, load\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usa frecuencia de palabras\n",
    "def create_tf_idf(list_text):\n",
    "    vectorizer = TfidfVectorizer(use_idf=False, norm=None, ngram_range=(1, 1)) # use_idf=true ponderacion de frecuancia de palabras en documentos\n",
    "    tfidf = vectorizer.fit(list(list_text))\n",
    "    vectores_tfidf=vectorizer.transform(list_text)\n",
    "    dump(tfidf,'tfidf_model.joblib')\n",
    "    print('Fue creado modelo TF-IDF')\n",
    "    #vectores_tfidf=list(matrix)\n",
    "    #print(len(vectores_tfidf))\n",
    "    return vectores_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna un vector TF-IDF \n",
    "def get_vector_tfidf(list_text):\n",
    "    tfidf=load('tfidf_model.joblib')# Ojo cuidado, solo cargar solo una vez\n",
    "    words_ntf=[x for x in list_text.split() if x not in tfidf.get_feature_names()] # Palabras que no estan en el vocabulario del modelo\n",
    "    return tfidf.transform([list_text]).toarray()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return sum([i*j for i,j in zip(a, b)])/(math.sqrt(sum([i*i for i in a]))* math.sqrt(sum([i*i for i in b])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leyendo los datos CSV\n",
    "datos_notacion = pd.read_csv('natacion_suicidio.csv')\n",
    "datos_general = pd.read_csv('suicidio_todo.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frase</th>\n",
       "      <th>tweet_clean</th>\n",
       "      <th>suicidio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cansado de estar solo</td>\n",
       "      <td>louis espero no estar pidiendo mucho solo quie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cansado de estar solo</td>\n",
       "      <td>estoy super cansado cansado de la gente cansad...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    frase                                        tweet_clean  \\\n",
       "7   cansado de estar solo  louis espero no estar pidiendo mucho solo quie...   \n",
       "17  cansado de estar solo  estoy super cansado cansado de la gente cansad...   \n",
       "\n",
       "    suicidio  \n",
       "7          1  \n",
       "17         1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seleccionamos solo los datos que tienen tendencia suicida\n",
    "selec_dat_1=datos_notacion.loc[datos_notacion['suicidio'] == 1]\n",
    "selec_dat_1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>frase</th>\n",
       "      <th>idtw</th>\n",
       "      <th>tweet</th>\n",
       "      <th>nombre</th>\n",
       "      <th>fecha</th>\n",
       "      <th>tweet_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4901</td>\n",
       "      <td>dormir y nunca mas despertar</td>\n",
       "      <td>1185025213177704448</td>\n",
       "      <td>Ganas de dormir y no despertar nunca más</td>\n",
       "      <td>darafiorodri</td>\n",
       "      <td>18/10/2019 02:50</td>\n",
       "      <td>ganas de dormir y no despertar nunca más</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4902</td>\n",
       "      <td>dormir y nunca mas despertar</td>\n",
       "      <td>1185004540707430400</td>\n",
       "      <td>RT @MarioMcmv75: Así es NUNCA MÁS NOS TRAGAMOS...</td>\n",
       "      <td>sanpascualitor</td>\n",
       "      <td>18/10/2019 01:27</td>\n",
       "      <td>así es nunca más nos tragamos y cerquita de di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                         frase                 idtw  \\\n",
       "0  4901  dormir y nunca mas despertar  1185025213177704448   \n",
       "1  4902  dormir y nunca mas despertar  1185004540707430400   \n",
       "\n",
       "                                               tweet          nombre  \\\n",
       "0           Ganas de dormir y no despertar nunca más    darafiorodri   \n",
       "1  RT @MarioMcmv75: Así es NUNCA MÁS NOS TRAGAMOS...  sanpascualitor   \n",
       "\n",
       "              fecha                                        tweet_clean  \n",
       "0  18/10/2019 02:50           ganas de dormir y no despertar nunca más  \n",
       "1  18/10/2019 01:27  así es nunca más nos tragamos y cerquita de di...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos_general.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fue creado modelo TF-IDF\n"
     ]
    }
   ],
   "source": [
    "# Agrupamos y guardamos en un diccionario, cada elemento del diccionario es una lista\n",
    "dict_general=datos_general.groupby('frase')['tweet_clean'].apply(list).to_dict()\n",
    "\n",
    "# Extraemos todo los tweets para crear el vocabulario para TF-IDF\n",
    "text_todo=list(datos_general.tweet_clean.values.astype('U'))\n",
    "vectores_tfidf=create_tf_idf(text_todo) #vocubulario total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cansado de estar solo\n",
      "cansado de estar solo\n"
     ]
    }
   ],
   "source": [
    "similares=defaultdict(list) #inicializamos un diccionario de listas para guardar la data necesaria\n",
    "for i,j in zip(list(selec_dat_1.frase),list(selec_dat_1.tweet_clean)):\n",
    "    vec_selec=get_vector_tfidf(j)\n",
    "    print(i)\n",
    "    for x in dict_general[i]:\n",
    "        vec_todo_j=get_vector_tfidf(x)\n",
    "        simi=cosine_similarity(vec_selec,vec_todo_j)[0][0]\n",
    "        if simi>0.6 and simi<0.95: # guardamos todos los tweets con similaridad alta, pero menor 0.95 que podria ser la misma frase\n",
    "            similares['frase'].append(i)\n",
    "            similares['tweet_anotado'].append(j)\n",
    "            similares['tweet_similar'].append(x)\n",
    "            similares['similaridad'].append(simi)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertimos el diccionario de listas a un Dataframe e lo guardamos como CSV\n",
    "findal_dt=pd.DataFrame.from_dict(similares,orient='index').transpose()\n",
    "findal_dt.to_csv(r'datos_similares_notados.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
