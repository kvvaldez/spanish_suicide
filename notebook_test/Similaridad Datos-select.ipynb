{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "from joblib import dump, load\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usa frecuencia de palabras\n",
    "def create_tf_idf(list_text):\n",
    "    vectorizer = TfidfVectorizer(use_idf=False, norm=None, ngram_range=(1, 1)) # use_idf=true ponderacion de frecuancia de palabras en documentos\n",
    "    tfidf = vectorizer.fit(list(list_text))\n",
    "    vectores_tfidf=vectorizer.transform(list_text)\n",
    "    dump(tfidf,'tfidf_model2joblib')\n",
    "    print('Fue creado modelo TF-IDF')\n",
    "    #vectores_tfidf=list(matrix)\n",
    "    #print(len(vectores_tfidf))\n",
    "    return vectores_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retorna un vector TF-IDF \n",
    "def get_vector_tfidf(list_text):\n",
    "    tfidf=load('tfidf_model2.joblib')# Ojo cuidado, solo cargar solo una vez\n",
    "    words_ntf=[x for x in list_text.split() if x not in tfidf.get_feature_names()] # Palabras que no estan en el vocabulario del modelo\n",
    "    return tfidf.transform([list_text]).toarray()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return sum([i*j for i,j in zip(a, b)])/(math.sqrt(sum([i*i for i in a]))* math.sqrt(sum([i*i for i in b])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leyendo los datos CSV\n",
    "datos_notacion = pd.read_csv('natacion_suicidio.csv')\n",
    "datos_general = pd.read_csv('suicidio_todo.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3957\n",
      "381409\n"
     ]
    }
   ],
   "source": [
    "print(datos_notacion.size)\n",
    "print(datos_general.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frase</th>\n",
       "      <th>tweet_clean</th>\n",
       "      <th>suicidio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cansado de estar solo</td>\n",
       "      <td>louis espero no estar pidiendo mucho solo quie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cansado de estar solo</td>\n",
       "      <td>estoy super cansado cansado de la gente cansad...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    frase                                        tweet_clean  \\\n",
       "7   cansado de estar solo  louis espero no estar pidiendo mucho solo quie...   \n",
       "17  cansado de estar solo  estoy super cansado cansado de la gente cansad...   \n",
       "\n",
       "    suicidio  \n",
       "7          1  \n",
       "17         1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seleccionamos solo los datos que tienen tendencia suicida\n",
    "selec_dat_1=datos_notacion.loc[datos_notacion['suicidio'] == 1]\n",
    "selec_dat_1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>frase</th>\n",
       "      <th>idtw</th>\n",
       "      <th>tweet</th>\n",
       "      <th>nombre</th>\n",
       "      <th>fecha</th>\n",
       "      <th>tweet_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4901</td>\n",
       "      <td>dormir y nunca mas despertar</td>\n",
       "      <td>1185025213177704448</td>\n",
       "      <td>Ganas de dormir y no despertar nunca más</td>\n",
       "      <td>darafiorodri</td>\n",
       "      <td>18/10/2019 02:50</td>\n",
       "      <td>ganas de dormir y no despertar nunca más</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4902</td>\n",
       "      <td>dormir y nunca mas despertar</td>\n",
       "      <td>1185004540707430400</td>\n",
       "      <td>RT @MarioMcmv75: Así es NUNCA MÁS NOS TRAGAMOS...</td>\n",
       "      <td>sanpascualitor</td>\n",
       "      <td>18/10/2019 01:27</td>\n",
       "      <td>así es nunca más nos tragamos y cerquita de di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                         frase                 idtw  \\\n",
       "0  4901  dormir y nunca mas despertar  1185025213177704448   \n",
       "1  4902  dormir y nunca mas despertar  1185004540707430400   \n",
       "\n",
       "                                               tweet          nombre  \\\n",
       "0           Ganas de dormir y no despertar nunca más    darafiorodri   \n",
       "1  RT @MarioMcmv75: Así es NUNCA MÁS NOS TRAGAMOS...  sanpascualitor   \n",
       "\n",
       "              fecha                                        tweet_clean  \n",
       "0  18/10/2019 02:50           ganas de dormir y no despertar nunca más  \n",
       "1  18/10/2019 01:27  así es nunca más nos tragamos y cerquita de di...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos_general.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling_k_elements(group, k=200): \n",
    "    if len(group) < k:\n",
    "        return group\n",
    "    return group.sample(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fue creado modelo TF-IDF\n"
     ]
    }
   ],
   "source": [
    "# Agrupamos y guardamos en un diccionario, cada elemento del diccionario es una lista\n",
    "dict_general = datos_general.groupby('frase').apply(sampling_k_elements).reset_index(drop=True)\n",
    "dict_general=dict_general.groupby('frase')['tweet_clean'].apply(list).to_dict()\n",
    "\n",
    "# Extraemos todo los tweets para crear el vocabulario para TF-IDF\n",
    "text_todo=list(datos_general.tweet_clean.values.astype('U'))\n",
    "vectores_tfidf=create_tf_idf(text_todo) #vocubulario total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cansado de estar solo 145\n",
      "dormir y nunca mas despertar 52\n",
      "hacerme daño 200\n",
      "la vida es muy dura 200\n",
      "la vida no tiene sentido 200\n",
      "la vida no vale nada 200\n",
      "lastimarme 200\n",
      "listo para morir 118\n",
      "matarme 200\n",
      "me estoy ahogando 200\n",
      "me odio a mi mismo 200\n",
      "me odio yo mismo 200\n",
      "me voy ahora 200\n",
      "mi muerte 200\n",
      "mi vida consiste en nada 11\n",
      "mi vida es asi de miserable 21\n",
      "mi vida no tiene sentido 200\n",
      "mi vida no vale 200\n",
      "morir en mi sueño 116\n",
      "nada por lo que vivir 200\n",
      "no quiero continuar 200\n",
      "no quiero despertar 200\n",
      "no quiero estar aqui 200\n",
      "no quiero estar mas aqui 182\n",
      "no quiero estar vivo 164\n",
      "no quiero existir 200\n",
      "no quiero intentarlo mas 76\n",
      "no quiero seguir  200\n",
      "no quiero vivir 200\n",
      "no quiero vivir mas 200\n",
      "no soporto mas 200\n",
      "no vale la pena seguir viviendo 21\n",
      "no vale la pena vivir 200\n",
      "no valgo nada 200\n",
      "odio mi vida 200\n",
      "parar el dolor 188\n",
      "pensando en el suicidio 112\n",
      "podria quedarme solo dormido 1\n",
      "poner fin a esto 200\n",
      "por que debería seguir viviendo 16\n",
      "que esta mal conmigo 200\n",
      "que tengo de malo 200\n",
      "querer morir 200\n",
      "queria morir 200\n",
      "queriendome matar 55\n",
      "quiero desaparecer 200\n",
      "quiero estar muerto 111\n",
      "quiero irme 200\n",
      "quiero morir 200\n",
      "quiero que termine 200\n",
      "quiero terminar con esta pesadilla 3\n",
      "quiero terminarlo 200\n",
      "realmente necesito morir 15\n",
      "solo quiero dormir 200\n",
      "solo quiero rendirme 28\n",
      "suicida 200\n",
      "suicidarme 200\n",
      "terminar con mi vida 200\n",
      "terminar con todo 200\n",
      "terminar todo 200\n",
      "ya no puedo hacer esto 200\n"
     ]
    }
   ],
   "source": [
    "for x in dict_general.keys():\n",
    "    print(x,len(dict_general[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no quiero seguir'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(selec_dat_1.frase)[95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cansado de estar solo\n",
      "cansado de estar solo\n",
      "dormir y nunca mas despertar\n",
      "dormir y nunca mas despertar\n",
      "dormir y nunca mas despertar\n",
      "dormir y nunca mas despertar\n",
      "dormir y nunca mas despertar\n",
      "dormir y nunca mas despertar\n",
      "dormir y nunca mas despertar\n",
      "dormir y nunca mas despertar\n",
      "dormir y nunca mas despertar\n",
      "dormir y nunca mas despertar\n",
      "dormir y nunca mas despertar\n",
      "dormir y nunca mas despertar\n",
      "dormir y nunca mas despertar\n",
      "dormir y nunca mas despertar\n",
      "dormir y nunca mas despertar\n",
      "dormir y nunca mas despertar\n",
      "dormir y nunca mas despertar\n",
      "hacerme daño\n",
      "hacerme daño\n",
      "hacerme daño\n",
      "hacerme daño\n",
      "hacerme daño\n",
      "la vida no tiene sentido\n",
      "la vida no tiene sentido\n",
      "la vida no tiene sentido\n",
      "la vida no tiene sentido\n",
      "lastimarme\n",
      "lastimarme\n",
      "listo para morir\n",
      "listo para morir\n",
      "listo para morir\n",
      "listo para morir\n",
      "matarme\n",
      "matarme\n",
      "matarme\n",
      "matarme\n",
      "matarme\n",
      "matarme\n",
      "matarme\n",
      "matarme\n",
      "matarme\n",
      "matarme\n",
      "matarme\n",
      "matarme\n",
      "matarme\n",
      "matarme\n",
      "matarme\n",
      "matarme\n",
      "me estoy ahogando\n",
      "me estoy ahogando\n",
      "me estoy ahogando\n",
      "me estoy ahogando\n",
      "me estoy ahogando\n",
      "me estoy ahogando\n",
      "me odio a mi mismo\n",
      "me odio a mi mismo\n",
      "me odio a mi mismo\n",
      "me odio a mi mismo\n",
      "me odio a mi mismo\n",
      "me odio a mi mismo\n",
      "me odio a mi mismo\n",
      "me voy ahora\n",
      "mi muerte\n",
      "mi muerte\n",
      "mi vida consiste en nada\n",
      "mi vida consiste en nada\n",
      "mi vida es asi de miserable\n",
      "mi vida es asi de miserable\n",
      "mi vida es asi de miserable\n",
      "mi vida no tiene sentido\n",
      "mi vida no tiene sentido\n",
      "mi vida no tiene sentido\n",
      "no quiero continuar\n",
      "no quiero despertar\n",
      "no quiero despertar\n",
      "no quiero despertar\n",
      "no quiero despertar\n",
      "no quiero despertar\n",
      "no quiero estar aqui\n",
      "no quiero estar mas aqui\n",
      "no quiero estar mas aqui\n",
      "no quiero estar mas aqui\n",
      "no quiero existir\n",
      "no quiero existir\n",
      "no quiero existir\n",
      "no quiero existir\n",
      "no quiero existir\n",
      "no quiero existir\n",
      "no quiero existir\n",
      "no quiero existir\n",
      "no quiero existir\n",
      "no quiero seguir\n",
      "no quiero seguir\n",
      "no quiero seguir\n",
      "no quiero vivir\n",
      "no quiero vivir\n",
      "no quiero vivir mas\n",
      "no quiero vivir mas\n",
      "no quiero vivir mas\n",
      "no quiero vivir mas\n",
      "no quiero vivir mas\n",
      "no quiero vivir mas\n",
      "no soporto mas\n",
      "no soporto mas\n",
      "no vale la pena seguir viviendo\n",
      "no vale la pena seguir viviendo\n",
      "no vale la pena seguir viviendo\n",
      "no vale la pena seguir viviendo\n",
      "no vale la pena seguir viviendo\n",
      "no vale la pena vivir\n",
      "no valgo nada\n",
      "no valgo nada\n",
      "no valgo nada\n",
      "no valgo nada\n",
      "no valgo nada\n",
      "no valgo nada\n",
      "no valgo nada\n",
      "no valgo nada\n",
      "odio mi vida\n",
      "pensando en el suicidio\n",
      "pensando en el suicidio\n",
      "pensando en el suicidio\n",
      "que esta mal conmigo\n",
      "que tengo de malo\n",
      "que tengo de malo\n",
      "que tengo de malo\n",
      "querer morir\n",
      "querer morir\n",
      "querer morir\n",
      "queriendome matar\n",
      "queriendome matar\n",
      "queriendome matar\n",
      "queriendome matar\n",
      "queriendome matar\n",
      "queriendome matar\n",
      "quiero desaparecer\n",
      "quiero desaparecer\n",
      "quiero desaparecer\n",
      "quiero desaparecer\n",
      "quiero desaparecer\n",
      "quiero desaparecer\n",
      "quiero desaparecer\n",
      "quiero desaparecer\n",
      "quiero desaparecer\n",
      "quiero desaparecer\n",
      "quiero desaparecer\n",
      "quiero desaparecer\n",
      "quiero desaparecer\n",
      "quiero estar muerto\n",
      "quiero estar muerto\n",
      "quiero estar muerto\n",
      "quiero estar muerto\n",
      "quiero estar muerto\n",
      "quiero morir\n",
      "quiero morir\n",
      "quiero morir\n",
      "quiero morir\n",
      "quiero morir\n",
      "quiero morir\n",
      "quiero morir\n",
      "solo quiero dormir\n",
      "solo quiero rendirme\n",
      "solo quiero rendirme\n",
      "suicida\n",
      "suicidarme\n",
      "suicidarme\n",
      "suicidarme\n",
      "suicidarme\n",
      "suicidarme\n",
      "suicidarme\n",
      "suicidarme\n",
      "suicidarme\n",
      "suicidarme\n",
      "suicidarme\n",
      "suicidarme\n"
     ]
    }
   ],
   "source": [
    "similares=defaultdict(list) #inicializamos un diccionario de listas para guardar la data necesaria\n",
    "for i,j in zip(list(selec_dat_1.frase),list(selec_dat_1.tweet_clean)):\n",
    "    vec_selec=get_vector_tfidf(j)\n",
    "    print(i)\n",
    "    if i in dict_general:\n",
    "        for x in dict_general[i]:\n",
    "            vec_todo_j=get_vector_tfidf(x)\n",
    "            simi=cosine_similarity(vec_selec,vec_todo_j)[0][0]\n",
    "            if simi>0.6 and simi<0.95 and x not in similares['tweet_similar']: # guardamos todos los tweets con similaridad alta, pero menor 0.95 que podria ser la misma frase\n",
    "                similares['frase'].append(i)\n",
    "                similares['tweet_anotado'].append(j)\n",
    "                similares['tweet_similar'].append(x)\n",
    "                similares['similaridad'].append(simi)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertimos el diccionario de listas a un Dataframe e lo guardamos como CSV\n",
    "findal_dt=pd.DataFrame.from_dict(similares,orient='index').transpose()\n",
    "findal_dt.to_csv(r'datos_similares_notados_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'aaa' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-972a1a11f199>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maaa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'aaa' is not defined"
     ]
    }
   ],
   "source": [
    "aaa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparar data para re-anotacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_notar1 = pd.read_csv('datos_nota_sim.csv') \n",
    "datos_notar2 = pd.read_csv('datos_similares_notados_2.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ya_notados=list(datos_notar1.tweet_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_notados=list(datos_notar2.tweet_similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "457"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(ya_notados)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuevos=[]\n",
    "for i in no_notados:\n",
    "    if i not in ya_notados:\n",
    "        nuevos.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "298"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nuevos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx = pd.DataFrame({'tweet_clean':nuevos})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xxx.to_csv(r'mas2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
